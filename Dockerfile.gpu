# 使用 CUDA 支持的基礎映像
FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

# 設置工作目錄
WORKDIR /app

# 安裝 Python 和系統依賴
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.9 \
    python3-pip \
    python3-setuptools \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 創建符號連接
RUN ln -s /usr/bin/python3.9 /usr/bin/python

# 複製 requirements 檔案
COPY requirements.txt .

# 安裝基礎依賴
RUN pip3 install --no-cache-dir flask==2.3.3 gunicorn==21.2.0 requests>=2.31.0

# 使用預構建的 CUDA 支持版 llama-cpp-python 包
RUN pip3 install --no-cache-dir llama-cpp-python==0.2.38 --extra-index-url https://wheels.rasa.com/llama-cpp-python/cuda/

# 複製應用程式代碼
COPY app.py .

# 創建模型目錄
RUN mkdir -p models

# 設置環境變數
ENV PYTHONUNBUFFERED=1
ENV GGUF_FILE=models/LLaMAX3-8B-Alpaca.Q8_0.gguf
ENV N_GPU_LAYERS=-1
ENV N_THREADS=8
ENV PORT=5000

# 暴露端口
EXPOSE ${PORT}

# 健康檢查
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:${PORT}/health || exit 1

# 運行應用程式
CMD ["gunicorn", "--bind", "0.0.0.0:${PORT}", "app:app", "--timeout", "120"]
